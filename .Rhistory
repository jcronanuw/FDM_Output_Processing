#Libraries
library(tidyverse)
library(readxl)
library(googledrive)#used to access files in Google Drive
#load data
weights <- read_excel("C:/Users/jcronan/Documents/GitHub/lidar_fuel_moisture_temp/GoogleDrive_TempDownloads/Fuel_moisture_weights.xlsx")
weights <- write_csv(weights, "C:/Users/jcronan/Documents/GitHub/lidar_fuel_moisture_temp/GoogleDrive_TempDownloads/Fuel_moisture_weights.csv")
weights <- read.csv("C:/Users/jcronan/Documents/GitHub/lidar_fuel_moisture_temp/GoogleDrive_TempDownloads/Fuel_moisture_weights.csv")
weights <- read_excel("C:/Users/jcronan/Documents/GitHub/lidar_fuel_moisture_qaqc/GoogleDrive_TempDownloads/Fuel_moisture_weights.xlsx")
weights <- write_csv(weights, "C:/Users/jcronan/Documents/GitHub/lidar_fuel_moisture_qaqc/GoogleDrive_TempDownloads/Fuel_moisture_weights.csv")
weights <- read.csv("C:/Users/jcronan/Documents/GitHub/lidar_fuel_moisture_qaqc/GoogleDrive_TempDownloads/Fuel_moisture_weights.csv")
#load data
tare <- read_excel("C:/Users/jcronan/Documents/GitHub/lidar_fuel_moisture_qaqc/GoogleDrive_TempDownloads/drying_trays.xlsx")
tare <- write_csv(tare, "C:/Users/jcronan/Documents/GitHub/lidar_fuel_moisture_qaqc/GoogleDrive_TempDownloads/drying_trays.csv")
tare <- read.csv("C:/Users/jcronan/Documents/GitHub/lidar_fuel_moisture_qaqc/GoogleDrive_TempDownloads/drying_trays.csv")
#load data
dry.wts <- read_excel("C:/Users/jcronan/Documents/GitHub/lidar_fuel_moisture_qaqc/GoogleDrive_TempDownloads/dry_weights.xlsx")
dry.wts <- write_csv(dry.wts, "C:/Users/jcronan/Documents/GitHub/lidar_fuel_moisture_qaqc/GoogleDrive_TempDownloads/dry_weights.csv")
dry.wts <- read.csv("C:/Users/jcronan/Documents/GitHub/lidar_fuel_moisture_qaqc/GoogleDrive_TempDownloads/dry_weights.csv")
warnings()
head(dry.wts)
#Calculate standard deviation, number of samples, minimum value, and max value for gross weights by sample type, sample number, and
#scan time.
sstats.1 <- as.data.frame(weights %>%
group_by(sample.type, Sample, scan) %>%
summarise(sd = round(sd(gross.weight),2), n = n(), min = min(gross.weight), max = max(gross.weight)))
#Calculate range between min and max values for gross weight.
diff.1 <- sstats$max - sstats$min
#Combine with earlier object.
sstats.2 <- data.frame(sstats.1, data.range = diff.1)
#Do a histogram to see how gross weight spread
nf <- layout(matrix(c(1,2,3,4,5,6),3,2,byrow = TRUE), c(1,1,1), c(1,1), TRUE)
layout.show(nf)
hist(sstats.2$data.range[sstats.2$sample.type == "PB"], breaks = bs, main = "Pine Board")
hist(sstats.2$data.range[sstats.2$sample.type == "CC"], breaks = bs, main = "Cheese Cloth")
hist(sstats.2$data.range[sstats.2$sample.type == "DF"], breaks = bs, main = "Douglas-fir")
hist(sstats.2$data.range[sstats.2$sample.type == "PP"], breaks = bs, main = "Ponderosa Pine")
hist(sstats.2$data.range[sstats.2$sample.type == "SRO"], breaks = bs, main = "Southern Red Oak")
hist(sstats.2$data.range[sstats.2$sample.type == "LLP"], breaks = bs, main = "Longleaf Pine")
diff.1 <- sstats.1$max - sstats.1$min
sstats.2 <- data.frame(sstats.1, data.range = diff.1)
nf <- layout(matrix(c(1,2,3,4,5,6),3,2,byrow = TRUE), c(1,1,1), c(1,1), TRUE)
layout.show(nf)
hist(sstats.2$data.range[sstats.2$sample.type == "PB"], breaks = bs, main = "Pine Board")
hist(sstats.2$data.range[sstats.2$sample.type == "CC"], breaks = bs, main = "Cheese Cloth")
hist(sstats.2$data.range[sstats.2$sample.type == "DF"], breaks = bs, main = "Douglas-fir")
hist(sstats.2$data.range[sstats.2$sample.type == "PP"], breaks = bs, main = "Ponderosa Pine")
hist(sstats.2$data.range[sstats.2$sample.type == "SRO"], breaks = bs, main = "Southern Red Oak")
hist(sstats.2$data.range[sstats.2$sample.type == "LLP"], breaks = bs, main = "Longleaf Pine")
bs <- seq(1:60,1)
nf <- layout(matrix(c(1,2,3,4,5,6),3,2,byrow = TRUE), c(1,1,1), c(1,1), TRUE)
layout.show(nf)
hist(sstats.2$data.range[sstats.2$sample.type == "PB"], breaks = bs, main = "Pine Board")
hist(sstats.2$data.range[sstats.2$sample.type == "CC"], breaks = bs, main = "Cheese Cloth")
hist(sstats.2$data.range[sstats.2$sample.type == "DF"], breaks = bs, main = "Douglas-fir")
hist(sstats.2$data.range[sstats.2$sample.type == "PP"], breaks = bs, main = "Ponderosa Pine")
hist(sstats.2$data.range[sstats.2$sample.type == "SRO"], breaks = bs, main = "Southern Red Oak")
hist(sstats.2$data.range[sstats.2$sample.type == "LLP"], breaks = bs, main = "Longleaf Pine")
#Breaks for histogram
bs <- seq(1:60,1)
#Do a histogram to see how gross weight spread
nf <- layout(matrix(c(1,2,3,4,5,6),3,2,byrow = TRUE), c(1,1,1), c(1,1), TRUE)
layout.show(nf)
hist(sstats.2$data.range[sstats.2$sample.type == "PB"], breaks = bs, main = "Pine Board")
hist(sstats.2$data.range[sstats.2$sample.type == "CC"], breaks = bs, main = "Cheese Cloth")
hist(sstats.2$data.range[sstats.2$sample.type == "DF"], breaks = bs, main = "Douglas-fir")
hist(sstats.2$data.range[sstats.2$sample.type == "PP"], breaks = bs, main = "Ponderosa Pine")
hist(sstats.2$data.range[sstats.2$sample.type == "SRO"], breaks = bs, main = "Southern Red Oak")
hist(sstats.2$data.range[sstats.2$sample.type == "LLP"], breaks = bs, main = "Longleaf Pine")
bs <- seq(1,60,1)
#Do a histogram to see how gross weight spread
nf <- layout(matrix(c(1,2,3,4,5,6),3,2,byrow = TRUE), c(1,1,1), c(1,1), TRUE)
layout.show(nf)
hist(sstats.2$data.range[sstats.2$sample.type == "PB"], breaks = bs, main = "Pine Board")
hist(sstats.2$data.range[sstats.2$sample.type == "CC"], breaks = bs, main = "Cheese Cloth")
hist(sstats.2$data.range[sstats.2$sample.type == "DF"], breaks = bs, main = "Douglas-fir")
hist(sstats.2$data.range[sstats.2$sample.type == "PP"], breaks = bs, main = "Ponderosa Pine")
hist(sstats.2$data.range[sstats.2$sample.type == "SRO"], breaks = bs, main = "Southern Red Oak")
hist(sstats.2$data.range[sstats.2$sample.type == "LLP"], breaks = bs, main = "Longleaf Pine")
range(sstats.2$data.range)
bs <- seq(1,65,1)
bs
#Do a histogram to see how gross weight spread
nf <- layout(matrix(c(1,2,3,4,5,6),3,2,byrow = TRUE), c(1,1,1), c(1,1), TRUE)
layout.show(nf)
hist(sstats.2$data.range[sstats.2$sample.type == "PB"], breaks = bs, main = "Pine Board")
hist(sstats.2$data.range[sstats.2$sample.type == "CC"], breaks = bs, main = "Cheese Cloth")
hist(sstats.2$data.range[sstats.2$sample.type == "DF"], breaks = bs, main = "Douglas-fir")
hist(sstats.2$data.range[sstats.2$sample.type == "PP"], breaks = bs, main = "Ponderosa Pine")
hist(sstats.2$data.range[sstats.2$sample.type == "SRO"], breaks = bs, main = "Southern Red Oak")
hist(sstats.2$data.range[sstats.2$sample.type == "LLP"], breaks = bs, main = "Longleaf Pine")
#Breaks for histogram
bs <- seq(0,65,1)
#Do a histogram to see how gross weight spread
nf <- layout(matrix(c(1,2,3,4,5,6),3,2,byrow = TRUE), c(1,1,1), c(1,1), TRUE)
layout.show(nf)
hist(sstats.2$data.range[sstats.2$sample.type == "PB"], breaks = bs, main = "Pine Board")
hist(sstats.2$data.range[sstats.2$sample.type == "CC"], breaks = bs, main = "Cheese Cloth")
hist(sstats.2$data.range[sstats.2$sample.type == "DF"], breaks = bs, main = "Douglas-fir")
hist(sstats.2$data.range[sstats.2$sample.type == "PP"], breaks = bs, main = "Ponderosa Pine")
hist(sstats.2$data.range[sstats.2$sample.type == "SRO"], breaks = bs, main = "Southern Red Oak")
hist(sstats.2$data.range[sstats.2$sample.type == "LLP"], breaks = bs, main = "Longleaf Pine")
#Breaks for histogram
bs <- seq(0,65,1)
#Do a histogram to see how gross weight spread
nf <- layout(matrix(c(1,2,3,4,5,6),3,2,byrow = TRUE), c(1,1,1), c(1,1), TRUE)
layout.show(nf)
hist(sstats.2$data.range[sstats.2$sample.type == "PB"], breaks = bs, main = "Pine Board")
hist(sstats.2$data.range[sstats.2$sample.type == "CC"], breaks = bs, main = "Cheese Cloth")
hist(sstats.2$data.range[sstats.2$sample.type == "DF"], breaks = bs, main = "Douglas-fir")
hist(sstats.2$data.range[sstats.2$sample.type == "PP"], breaks = bs, main = "Ponderosa Pine")
hist(sstats.2$data.range[sstats.2$sample.type == "SRO"], breaks = bs, main = "Southern Red Oak")
hist(sstats.2$data.range[sstats.2$sample.type == "LLP"], breaks = bs, main = "Longleaf Pine")
sstats_noZero <- sstats.2[sstats.2$scan != "0",]
#How many samples exceed a gram difference
yellow.flags <- sstats.2[sstats.2$data.range > 2,]
#How many samples have yellow flags
length(yellow.flags[,1])
#Percent of samples with yellow flags
length(yellow.flags[,1])/length(sstats.2[,1])
#Samples for the zero hour scan can reasonably be expected to have different weights over the four scan locations because
#water was dripping from sample trays. Remove them
#How many samples exceed a gram difference
blue.flags <- sstats_noZero[sstats_noZero$data.range > 5,]
#How many samples have yellow flags
length(blue.flags[,1])
#Percent of samples with yellow flags
length(blue.flags[,1])/length(sstats.2[,1])
#Worst offenders: samples after 0-hr scan with range of weights exceeding 10 grams
red.flags <- sstats_noZero[sstats_noZero$data.range > 10,]
#How many samples have yellow flags
length(red.flags[,1])
#Percent of samples with yellow flags
length(red.flags[,1])/length(sstats.2[,1])
#3.3% of samples are in this category
#Start reviewing them
red.flags
###################################################################################################################################################
###################################################################################################################################################
###################################################################################################################################################
#QAQC - flag gross weight outliers among scan positions (3m , 6m, 9m, and 12m) for each sample at each scan time.
weights.llp[weights.llp$scan == 12,]
weights.llp <- filter(weights, sample.type == "LLP")
weights.llp <- inner_join(weights.llp, tare, by = "Sample")
weights.llp[weights.llp$scan == 12,]
weights.llp[weights.llp$Sample == 29 & weights.llp$scan %in% c(8,12),]
weights.llp$scan[561]
weights.llp$scan[561] <- "12"
weights.llp[weights.llp$Sample == 29 & weights.llp$scan %in% c(8,12),]
weights.llp[weights.llp$Sample == 29 & weights.llp$scan == 12,]
weights.llp[weights.llp$scan == 12,]
sstats.llp <- as.data.frame(weights.llp %>%
group_by(Sample) %>%
summarise(sd = round(sd(gross.weight),2)))
sstats.llp
sstats.llp <- as.data.frame(weights.llp %>%
group_by(Sample) %>%
summarise(median = round(median(gross.weight),2)))
sstats.llp
expand.grid(sstats.llp, 4)
?expand.grid
x <- seq(0, 10, length.out = 100)
y <- seq(-1, 1, length.out = 20)
x
y
x <- seq(0, 10, 1)
y <- seq(-1, 1, 1)
d1 <- expand.grid(x = x, y = y)
d1
expand.grid(c(3,6,9,12), sstats.llp$median)
expand.grid(location = c(3,6,9,12), median = sstats.llp$median)
llp.median <- expand.grid(location = c(3,6,9,12), median = sstats.llp$median)
weights.llp$gross.weight - llp.median$median
median(c(1,2,3,4))
weights.llp$gross.weight[weights.llp$Sample == 17]
weights.12 <- weights.llp[weights.llp$scan == "12",]
weights.12
sstats.llp <- as.data.frame(weights.12 %>%
group_by(Sample) %>%
summarise(median = round(median(gross.weight),2)))
sstats.llp
llp.median <- expand.grid(location = c(3,6,9,12), median = sstats.llp$median)
llp.median
weights.llp$gross.weight - llp.median$median
llp.median
weights.12$gross.weight - llp.median$median
diff.12 <- weights.12$gross.weight - llp.median$median
weights.12[diff.12 > 1]
diff.12 > 1
weights.12[diff.12 > 1,]
error.12 <- data.frame(error.12, dev = diff.12[diff.12 > 1,])
error.12 <- weights.12[diff.12 > 1,]
error.12 <- data.frame(error.12, dev = diff.12[diff.12 > 1,])
error.12 <- weights.12[diff.12 > 1]
error.12 <- data.frame(error.12, dev = diff.12[diff.12 > 1,])
error.12 <- weights.12[diff.12 > 1]
diff.12 <- weights.12$gross.weight - llp.median$median
error.12 <- weights.12[diff.12 > 1]
error.12 <- weights.12[diff.12 > 1,]
error.12 <- data.frame(error.12, dev = diff.12[diff.12 > 1,])
error.12 <- data.frame(error.12, dev = diff.12[diff.12 > 1])
error.12
weights.12[order(weights.12$gross.weight),]
llp.median[order(llp.median$median),]
sstats.llp
sstats.llp[order(sstats.llp$median),]
error.12[order(error.12$gross.weight),]
os.1 <- sstats.llp[order(sstats.llp$median),]
oe.1 <- error.12[order(error.12$gross.weight),]
os.2
os.1
os.1$median <- round(os.1$median,0)
os.1
oe.1$gross.weight <- round(o1.1$gross.weight,0)
oe.1 <- error.12[order(error.12$gross.weight),]
oe.1$gross.weight <- round(oe.1$gross.weight,0)
oe.1
match(oe.1$gross.weight, os.1$median)
os.1[os.1$median == 564]
os.1[os.1$median == 564,]
i <- 1
oe.1
i <- 3
os.1 <- sstats.llp[order(sstats.llp$median),]
oe.1 <- error.12[order(error.12$gross.weight),]
os.1
c(oe.1$gross.weight[i] - 1, oe.1$gross.weight[i] + 1)
os.1[os.1$median >= (oe.1$gross.weight[i] - 1) & os.1$median <= (oe.1$gross.weight[i] + 1),]
matches <- list()
wr <- 1
for(i in 1:length(oe.1$date))
{
matches[[i]] <- os.1[os.1$median >= (oe.1$gross.weight[i] - wr) & os.1$median <= (oe.1$gross.weight[i] + wr),]
}
matches
matches <- list()
wr <- 2
for(i in 1:length(oe.1$date))
{
matches[[i]] <- os.1[os.1$median >= (oe.1$gross.weight[i] - wr) & os.1$median <= (oe.1$gross.weight[i] + wr),]
}
matches
er <- 3#error range in grams
sstats.llp <- as.data.frame(weights.12 %>%
group_by(Sample) %>%
summarise(median = round(median(gross.weight),2)))
llp.median <- expand.grid(location = c(3,6,9,12), median = sstats.llp$median)
diff.12 <- weights.12$gross.weight - llp.median$median
error.12 <- weights.12[diff.12 > er,]
error.12 <- data.frame(error.12, dev = diff.12[diff.12 > er])
error.12
os.1 <- sstats.llp[order(sstats.llp$median),]
oe.1 <- error.12[order(error.12$gross.weight),]
matches <- list()
for(i in 1:length(oe.1$date))
{
matches[[i]] <- os.1[os.1$median >= (oe.1$gross.weight[i] - er) & os.1$median <= (oe.1$gross.weight[i] + er),]
}
matches
er <- 5#error range in grams
sstats.llp <- as.data.frame(weights.12 %>%
group_by(Sample) %>%
summarise(median = round(median(gross.weight),2)))
llp.median <- expand.grid(location = c(3,6,9,12), median = sstats.llp$median)
diff.12 <- weights.12$gross.weight - llp.median$median
error.12 <- weights.12[diff.12 > er,]
error.12 <- data.frame(error.12, dev = diff.12[diff.12 > er])
os.1 <- sstats.llp[order(sstats.llp$median),]
oe.1 <- error.12[order(error.12$gross.weight),]
matches <- list()
for(i in 1:length(oe.1$date))
{
matches[[i]] <- os.1[os.1$median >= (oe.1$gross.weight[i] - er) & os.1$median <= (oe.1$gross.weight[i] + er),]
}
matches
er <- 6#error range in grams
sstats.llp <- as.data.frame(weights.12 %>%
group_by(Sample) %>%
summarise(median = round(median(gross.weight),2)))
llp.median <- expand.grid(location = c(3,6,9,12), median = sstats.llp$median)
diff.12 <- weights.12$gross.weight - llp.median$median
error.12 <- weights.12[diff.12 > er,]
error.12 <- data.frame(error.12, dev = diff.12[diff.12 > er])
os.1 <- sstats.llp[order(sstats.llp$median),]
oe.1 <- error.12[order(error.12$gross.weight),]
matches <- list()
for(i in 1:length(oe.1$date))
{
matches[[i]] <- os.1[os.1$median >= (oe.1$gross.weight[i] - er) & os.1$median <= (oe.1$gross.weight[i] + er),]
}
matches
error.12
er <- 10#error range in grams
sstats.llp <- as.data.frame(weights.12 %>%
group_by(Sample) %>%
summarise(median = round(median(gross.weight),2)))
llp.median <- expand.grid(location = c(3,6,9,12), median = sstats.llp$median)
diff.12 <- weights.12$gross.weight - llp.median$median
error.12 <- weights.12[diff.12 > er,]
error.12 <- data.frame(error.12, dev = diff.12[diff.12 > er])
os.1 <- sstats.llp[order(sstats.llp$median),]
oe.1 <- error.12[order(error.12$gross.weight),]
matches <- list()
for(i in 1:length(oe.1$date))
{
matches[[i]] <- os.1[os.1$median >= (oe.1$gross.weight[i] - er) & os.1$median <= (oe.1$gross.weight[i] + er),]
}
matches
matches <- list()
for(i in 1:length(oe.1$date))
{
matches[[i]] <- os.1[os.1$median >= (oe.1$gross.weight[i] - er) & os.1$median <= (oe.1$gross.weight[i] + er),]
}
matches
library(tidyverse)
library(readxl)
library(googledrive)#used to access files in Google Drive
#Drive authorization -- provide authorization to access Google Drive
drive_auth()
#Set working drive
setwd("C:/Users/jcronan/Documents/GitHub/Quality_Control_3DF_Bulk_Density_Dataset/GoogleDrive_TempDownloads/")
install.packages("Hmisc", repos="http://cran.fhcrc.org/")
install.packages("GenKern", repos="http://cran.fhcrc.org/")
library(GenKern)#for nearest()
install.packages("KernSmooth", repos="http://cran.fhcrc.org/")
install.packages("KernSmooth", repos = "http://cran.fhcrc.org/")
install.packages("RTools", repos="http://cran.fhcrc.org/")
install.packages("Rtools", repos="http://cran.fhcrc.org/")
library(vegan)
install.packages('vegan')
library(vegan)
library(MASS)
library(ecodist)
install.packages('ecodist')
library(ecodist)
library(nortest)
install.packages('nortest')
library(nortest)
library(fields)
install.packages('fields')
library(fields)
install.packages('labdsv')
install.packages('PerformanceAnalytics')
library(raster)
tmp <- tempdir()
r <- raster(system.file("external/test.grd", package="raster"))
str(r)
r <- crop(r, extent(179880, 180800, 329880, 330840) )
str(r)
setwd("E:/FS_Desktop/D_Drive/usfs_cronan_gis/SEF/FDM_Dissertation_Runs/fdm_out_asc")
list_file <- list.files (getwd(), pattern = "*.asc", full.names = T)
list_file
list_file <- list.files (pattern = "*.asc", full.names = T)
list_file
list_file <- list.files (pattern = "*.asc", full.names = F)
list_file
list_file
substring(old_file[1],1)
old_file <- list.files (pattern = "*.asc", full.names = F)
substring(old_file[1],1)
substring(old_file[1],1,1)
substring(old_file,1,1)
?substring
new_file[i] <- paste(substring(old_file[1],1,1), substring(old_file[1],5,7), substring(old_file[1],9,11), substring(old_file[1],15,16)
)
new_file <- vector()
new_file[i] <- paste(substring(old_file[1],1,1), substring(old_file[1],5,7), substring(old_file[1],9,11), substring(old_file[1],15,16))
i <- 1
new_file[i] <- paste(substring(old_file[1],1,1), substring(old_file[1],5,7), substring(old_file[1],9,11), substring(old_file[1],15,16))
new_file
new_file <- vector()
new_file[i] <- paste(substring(old_file[1],1,1), substring(old_file[1],5,7), substring(old_file[1],10,12), substring(old_file[1],16,17), sep = "")
new_file
length(old_file[1])
new_file <- vector()
new_file[i] <- paste(substring(old_file[1],1,1), "_", substring(old_file[1],5,7), "_",
substring(old_file[1],10,12), "_", substring(old_file[1],16,17), sep = "")
new_file
new_file <- vector()
for(i in 1:length(old_file))
{
new_file[i] <- paste(substring(old_file[1],1,1), "_", substring(old_file[1],5,7), "_",
substring(old_file[1],10,12), "_", substring(old_file[1],16,17), sep = "")
}
file.rename(from = old_file, to = new_file)
#Open data
setwd("E:/FS_Desktop/D_Drive/usfs_cronan_gis/SEF/FDM_Dissertation_Runs/fdm_out_asc")
library(raster)
old_file <- list.files (pattern = "*.asc", full.names = F)
new_file <- vector()
for(i in 1:length(old_file))
{
new_file[i] <- paste(substring(old_file[1],1,1), "_", substring(old_file[1],5,7), "_",
substring(old_file[1],10,12), "_", substring(old_file[1],16,17), sep = "")
}
new_file
new_file <- vector()
for(i in 1:length(old_file))
{
new_file[i] <- paste(substring(old_file[i],1,1), "_", substring(old_file[i],5,7), "_",
substring(old_file[i],10,12), "_", substring(old_file[i],16,17), sep = "")
}
file.rename(from = old_file, to = new_file)
library(raster)
old_file <- list.files (pattern = "*.asc", full.names = F)
old_file
new_file <- vector()
for(i in 1:length(old_file))
{
new_file[i] <- paste(substring(old_file[i],1,1), "_", substring(old_file[i],5,7), "_",
substring(old_file[i],10,12), "_", substring(old_file[i],16,17), ".asc", sep = "")
}
file.rename(from = old_file, to = new_file)
install.packages("reticulate")
library(reticulate)
setwd("C:/Users/jcronan/OneDrive - USDA/Documents/GitHub/FDM_Output_Processing")
py_run_file("20170929_ascii_to_raster_batch")
Y
py_run_file("20170929_ascii_to_raster_batch")
n
